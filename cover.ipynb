{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "# 定义你的超参数\n",
    "batch_size = 8\n",
    "epochs = 10\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# 数据预处理\n",
    "transform = transforms.Compose([transforms.Resize((2048,2048)), \n",
    "                                transforms.ToTensor()])\n",
    "\n",
    "# 加载数据，注意你需要修改为你的实际数据路径\n",
    "train_data = datasets.ImageFolder(root='/datasets/score_data/cover-data/train', transform=transform)\n",
    "val_data = datasets.ImageFolder(root='/datasets/score_data/cover-data/val', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 选择预训练的模型，这里使用预训练的resnet18，你可以更改为其他的模型\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2) # 你的类别数为2，乐谱与封面\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 迁移到GPU\n",
    "device = torch.device(\"cuda:5\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # 前向传播\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print ('Loss: {:.4f}'.format(loss.item()))\n",
    "\n",
    "    # 在validation数据上评估模型\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Validation Accuracy on epoch [{}]: {}%'.format(epoch+1, 100 * correct / total))\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms,models\n",
    "from PIL import Image\n",
    "\n",
    "# 加载模型\n",
    "device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet18(pretrained=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_ftrs, 2)  # 你的类别数为2，乐谱与封面\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "model.to(device)\n",
    "model.eval()  # 设定模型为评估（预测）模式\n",
    "\n",
    "# 加载并预处理图片\n",
    "image_path = 'IMSLP64564_8.jpg'  # 你可以填入你希望测试的图片路径\n",
    "image = Image.open(image_path)\n",
    "transform = transforms.Compose([transforms.Resize((2048, 2048)), \n",
    "                                transforms.ToTensor()])\n",
    "image = transform(image).unsqueeze(0).to(device)  # 增加一个维度以匹配模型的输入维度，并转移到 GPU\n",
    "\n",
    "# 使用模型进行预测\n",
    "with torch.no_grad():\n",
    "    output = model(image)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    if predicted.item() == 1:\n",
    "        print(\"This image is a score.\")\n",
    "    else:\n",
    "        print(\"This image is not a score.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "# Initialize the model and load the state_dict\n",
    "device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet18(pretrained=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_ftrs, 2)  # Assuming you have 2 classes: score and cover\n",
    "model.load_state_dict(torch.load('2048-cover.pth', map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Define the transformation for the image\n",
    "transform = transforms.Compose([transforms.Resize((2048, 2048)), \n",
    "                                transforms.ToTensor()])\n",
    "\n",
    "# Function to process each image\n",
    "def process_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "\n",
    "    # Return the image path and its prediction\n",
    "    return image_path, predicted.item()\n",
    "\n",
    "# Directory containing images\n",
    "image_dir = '/datasets/score_data/hd_data/hd_data_jpg'\n",
    "output_dir = '/datasets/score_data/cover-data/cover'\n",
    "\n",
    "# Create the output directory if it does not exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Get the list of image files\n",
    "image_files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png'))]\n",
    "\n",
    "# Process images in parallel\n",
    "def move_non_score_images():\n",
    "    with ProcessPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "        for image_path, predicted in executor.map(process_image, image_files):\n",
    "            if predicted == 0:  # Assuming '0' is the class for non-score images\n",
    "                # Move non-score images to the new directory\n",
    "                os.rename(image_path, os.path.join(output_dir, os.path.basename(image_path)))\n",
    "\n",
    "move_non_score_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def process_image(image_path, device, model):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((2048, 2048)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "\n",
    "    return image_path, predicted.item()\n",
    "\n",
    "def main():\n",
    "    device = torch.device(\"cuda:5\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = models.resnet18(pretrained=False)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = torch.nn.Linear(num_ftrs, 2)\n",
    "    model.load_state_dict(torch.load('2048-cover.pth', map_location=device))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Paths setup\n",
    "    image_dir = '/datasets/score_data/hd_piano/hd_data_jpg'\n",
    "    output_dir = '/datasets/score_data/cover-data/cover'\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    image_files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "    \n",
    "    for image_path in image_files:\n",
    "        _, predicted = process_image(image_path, device, model)\n",
    "        if predicted == 0:  # Assuming '0' is the class for non-score images\n",
    "            shutil.copy2(image_path, os.path.join(output_dir, os.path.basename(image_path)))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zheqid/miniconda3/envs/bidiff/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/zheqid/miniconda3/envs/bidiff/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0164\n",
      "Loss: 0.0017\n",
      "Loss: 0.0039\n",
      "Loss: 0.0133\n",
      "Loss: 0.0027\n",
      "Loss: 0.0022\n",
      "Loss: 0.0008\n",
      "Loss: 10.3067\n",
      "Loss: 0.0026\n",
      "Loss: 0.0118\n",
      "完整的分类任务评测指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       cover       0.95      1.00      0.98        20\n",
      "       score       1.00      0.97      0.98        30\n",
      "\n",
      "    accuracy                           0.98        50\n",
      "   macro avg       0.98      0.98      0.98        50\n",
      "weighted avg       0.98      0.98      0.98        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# 定义你的超参数\n",
    "batch_size = 8\n",
    "epochs = 10\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# 数据预处理\n",
    "transform = transforms.Compose([transforms.Resize((2048,2048)), \n",
    "                                transforms.ToTensor()])\n",
    "\n",
    "# 加载数据，注意你需要修改为你的实际数据路径\n",
    "train_data = datasets.ImageFolder(root='/datasets/score_data/cover-data/train', transform=transform)\n",
    "val_data = datasets.ImageFolder(root='/datasets/score_data/cover-data/val', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 选择预训练的模型，这里使用预训练的resnet18\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2) # 类别数为2，乐谱与封面\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 迁移到GPU\n",
    "device = torch.device(\"cuda:5\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 用于存储预测和真实标签的列表\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # 前向传播\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print ('Loss: {:.4f}'.format(loss.item()))\n",
    "\n",
    "# 在validation数据上评估模型\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # 将预测结果和真实标签添加到列表中\n",
    "        y_pred.extend(predicted.view(-1).cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "# 输出分类报告\n",
    "print('完整的分类任务评测指标：')\n",
    "print(classification_report(y_true, y_pred, target_names=val_data.classes))\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       cover     0.9524    1.0000    0.9756        20\n",
      "       score     1.0000    0.9667    0.9831        30\n",
      "\n",
      "    accuracy                         0.9800        50\n",
      "   macro avg     0.9762    0.9833    0.9793        50\n",
      "weighted avg     0.9810    0.9800    0.9801        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred, target_names=val_data.classes, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bidiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
